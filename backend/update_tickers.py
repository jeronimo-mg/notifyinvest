import requests
from bs4 import BeautifulSoup
import os

# 1. Base Knowledge (Common Names -> Tickers)
# This mapping helps the AI convert "Vale" to "VALE3"
BASE_MAPPING = {
    "VALE": "VALE3", "PETROBRAS": "PETR4", "ITAU": "ITUB4", "BRADESCO": "BBDC4", "AMBEV": "ABEV3",
    "BB": "BBAS3", "B3": "B3SA3", "WEG": "WEGE3", "ITAUSA": "ITSA4", "GERDAU": "GGBR4",
    "RENT3": "RENT3", "SUZANO": "SUZB3", "MAGALU": "MGLU3", "LOCALIZA": "RENT3", "HAPVIDA": "HAPV3",
    "RAIA": "RADL3", "TELEFONICA": "VIVT3", "TIM": "TIMS3", "AZUL": "AZUL4", "GOL": "GOLL4",
    "COGNA": "COGN3", "CSN": "CSNA3", "JBS": "JBSS3", "MARFRIG": "MRFG3", "MINERVA": "BEEF3",
    "EMBRAER": "EMBR3", "CCR": "CCRO3", "ELETROBRAS": "ELET3", "SABESP": "SBSP3", "CMIG": "CMIG4",
    "COPEL": "CPLE6", "HYPERA": "HYPE3", "LOJAS RENNER": "LREN3", "NATURA": "NTCO3", "TOTVS": "TOTS3",
    "VIBRA": "VBBR3", "ASSAI": "ASAI3", "CARREFOUR": "CRFB3", "ULTRAPAR": "UGPA3", "EQUATORIAL": "EQTL3",
    "RAIZEN": "RAIZ4", "COSAN": "CSAN3", "PRIO": "PRIO3", "3R": "RRRP3", "PETRORIO": "PRIO3", 
    "PETRORECONCAVO": "RECV3", "SANTANDER": "SANB11", "BTG": "BPAC11", "INTER": "INBR32", "NUBANK": "ROXO34",
    "BANCO INTER": "INBR32", "CVC": "CVCB3", "MRV": "MRVE3", "EZTEC": "EZTC3", "CYRELA": "CYRE3",
    "FLEURY": "FLRY3", "QUALICORP": "QUAL3", "REDE D'OR": "RDOR3", "SULAMERICA": "SULA11",
    "ENERGISA": "ENGI11", "CPFL": "CPFE3", "NEOENERGIA": "NEOE3", "ENGIE": "EGIE3", "SANEPAR": "SAPR11",
    "KLABIN": "KLBN11", "DEXCO": "DXCO3", "IRANI": "RANI3", "SLC": "SLCE3", "SAO MARTINHO": "SMTO3"
}

def fetch_fundamentus_tickers():
    """Scrapes all active tickers from Fundamentus."""
    url = "https://www.fundamentus.com.br/resultado.php"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        print(f"Fetching {url}...")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Fundamentus table rows: <tr><td><a href="detalhes.php?papel=ABBV34">ABBV34</a></td>...</tr>
        tickers = set()
        
        rows = soup.find_all('tr')
        for row in rows:
            cols = row.find_all('td')
            if cols:
                # First column is usually the ticker with a link
                link = cols[0].find('a')
                if link:
                    ticker = link.text.strip().upper()
                    if ticker:
                        tickers.add(ticker)
        
        print(f"Found {len(tickers)} tickers on Fundamentus.")
        return list(tickers)
        
    except Exception as e:
        print(f"Error fetching tickers: {e}")
        return []

def update_file(full_mapping):
    """Writes the updated Dictionary to b3_tickers.py"""
    file_path = os.path.join(os.path.dirname(__file__), "b3_tickers.py")
    
    with open(file_path, "w", encoding='utf-8') as f:
        f.write("# Auto-generated by update_tickers.py\n")
        f.write("# Contains Common Name -> Ticker mapping AND Ticker -> Ticker validation\n")
        f.write("B3_TICKERS = {\n")
        
        # Sort for cleanliness
        keys = sorted(full_mapping.keys())
        for k in keys:
            f.write(f'    "{k}": "{full_mapping[k]}",\n')
            
        f.write("}\n")
    
    print(f"Successfully wrote {len(full_mapping)} entries to {file_path}")

def main():
    print("--- Updating B3 Ticker List ---")
    
    # 1. Start with Base Mapping
    final_map = BASE_MAPPING.copy()
    
    # 2. Fetch All Tickers
    all_tickers = fetch_fundamentus_tickers()
    
    # 3. Add Ticker -> Ticker identity (e.g. "WEGE3": "WEGE3") for validation
    for t in all_tickers:
        final_map[t] = t
        
        # Also add "WEGE": "WEGE3" (4-letter prefix) if not already mapped?
        # Maybe risky. Let's stick to identity.
        
    update_file(final_map)

if __name__ == "__main__":
    main()
